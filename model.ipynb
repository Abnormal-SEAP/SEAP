{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7aedd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import dgl\n",
    "import torch as th\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1bd089",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c95e41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = np.load(\"emb.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2d470a",
   "metadata": {},
   "source": [
    "# Heterogeneous Graph Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8765a046",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_edges['edge_full_type'].unique()[0:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bfa8f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_sum = 0\n",
    "for etype in df_edges['edge_full_type'].unique()[0:-1]:\n",
    "    num = df_edges[df_edges.edge_full_type == etype].edge.nunique()\n",
    "    node_sum += num\n",
    "    print(\"node\", etype, num)\n",
    "    print(\"edge\", etype, df_edges[df_edges.edge_full_type == etype].shape[0])\n",
    "print(node_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3e455f",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge2type = {}\n",
    "\n",
    "mapping_node = {v:u+len(mapping_cust) for u,v in enumerate(df_edges_het.edge.unique())}\n",
    "mapping_edge_type = {v:u for u,v in enumerate(df_edges['edge_full_type'].unique()[0:-1])}\n",
    "\n",
    "edge_src = list(map(lambda x:mapping_cust[x], df_edges_het.cust_id.to_numpy()))\n",
    "edge_dst = list(map(lambda x:mapping_node[x], df_edges_het.edge.to_numpy()))\n",
    "edge_type = list(map(lambda x:mapping_edge_type[x], df_edges_het.edge_full_type.to_numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2c25f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "txn_set = set()\n",
    "\n",
    "txn_src = df_edges_trx.src_value.to_numpy()\n",
    "txn_dst = df_edges_trx.dst_value.to_numpy()\n",
    "for index, txn in enumerate(txn_src):\n",
    "    if txn in mapping_cust and txn_dst[index] in mapping_cust:\n",
    "        cust_src = mapping_cust[txn]\n",
    "        cust_dst = mapping_cust[txn_dst[index]]\n",
    "        if (cust_src, cust_dst) not in txn_set and (cust_dst, cust_src) not in txn_set:\n",
    "            edge_src.append(cust_src)\n",
    "            edge_dst.append(cust_dst)\n",
    "            edge_type.append(len(mapping_edge_type))\n",
    "            txn_set.add((cust_src, cust_dst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76fd0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_src_bid = edge_src + edge_dst\n",
    "edge_dst_bid = edge_dst + edge_src\n",
    "edge_type_bid = edge_type + [etype + len(mapping_edge_type) + 1 for etype in edge_type]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c49640f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for src, dst, etype in zip(edge_src_bid, edge_dst_bid, edge_type_bid):\n",
    "    edge2type[(src,dst)] = etype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd829acd",
   "metadata": {},
   "source": [
    "# Clustering for Abnormal Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78cbe3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "from typing import List, Set, Dict, Union\n",
    "\n",
    "import numpy as np\n",
    "import tqdm\n",
    "from scipy import sparse as sp\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "def get_comm_feature(nodes: List[int], scores: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Compute the distribution of edge types as the community feature.\"\n",
    "    \"\"\"\n",
    "    nodes = set(nodes)\n",
    "    arr = np.mean([scores[u] for u in nodes],axis=0)\n",
    "    return arr\n",
    "\n",
    "\n",
    "def get_patterns(comms: List[List[int]],\n",
    "                 node_labels: np.ndarray, n_patterns: int) -> (np.ndarray, List[List[int]], np.ndarray):\n",
    "    \"\"\"\n",
    "    Compute community features and use k-means to get patterns' features, size distributions, and supports.\n",
    "    \"\"\"\n",
    "    comm_features = [get_comm_feature(nodes, node_labels) for nodes in comms]\n",
    "    k_means = KMeans(n_patterns)\n",
    "    comm_labels = k_means.fit_predict(comm_features)\n",
    "    pattern_features = k_means.cluster_centers_\n",
    "    pattern_sizes = [[] for _ in range(n_patterns)]\n",
    "    pattern_support = np.zeros(n_patterns)\n",
    "    for i, label in enumerate(comm_labels):\n",
    "        pattern_support[label] += 1\n",
    "        pattern_sizes[label].append(len(comms[i]))\n",
    "    return pattern_features, pattern_sizes, pattern_support\n",
    "\n",
    "\n",
    "def compute_node_pattern_score(pattern_features: np.ndarray,\n",
    "                               adj_mat: sp.spmatrix,\n",
    "                               neighbors: Dict[int, Set[int]],\n",
    "                               scores:np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Scoring nodes based on local structures.\n",
    "    \"\"\"\n",
    "\n",
    "    n_nodes = adj_mat.shape[0]\n",
    "    # score of center node\n",
    "    node_local_features = np.array(scores, dtype=np.float64)\n",
    "    for u in tqdm.tqdm(range(n_nodes), desc='NodeLocalFeature'):\n",
    "        node_local_features[u] += np.sum([scores[v] for v in neighbors[u]], axis=0)\n",
    "    # First Order: Pass 1 in the paper\n",
    "    # @ 矩阵-向量乘法\n",
    "    node_first_order_scores = euclidean_distances(node_local_features, pattern_features)\n",
    "    # Second Order: Pass 2 in the paper\n",
    "    deg_vec = np.array(adj_mat.sum(1)).squeeze()\n",
    "    # diags 提取对角线或构造对角线数组。\n",
    "    node_second_order_scores = sp.diags((adj_mat @ deg_vec) ** -1) @ adj_mat @ (\n",
    "            deg_vec[:, None] * node_first_order_scores)\n",
    "    node_pattern_scores = node_first_order_scores + node_second_order_scores\n",
    "    return node_pattern_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5fe13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = np.load(\"emb.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e695f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "comm_features = [get_comm_feature(nodes, emb) for nodes in new_groups]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b4e3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"comm_features.npy\", comm_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab00641",
   "metadata": {},
   "outputs": [],
   "source": [
    "SSE = []  \n",
    "for k in range(2,20):\n",
    "    estimator = KMeans(n_clusters=k)  \n",
    "    estimator.fit(comm_features)\n",
    "    SSE.append(estimator.inertia_) \n",
    "X = range(2,20)\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('SSE')\n",
    "plt.plot(X,SSE,'o-')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45805c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score   \n",
    "scores = []\n",
    "models = []\n",
    "\n",
    "for i in range(2, 20):\n",
    "    cluster = KMeans(n_clusters=i).fit(comm_features)\n",
    "    y_pred = cluster.labels_\n",
    "    centroid = cluster.cluster_centers_\n",
    "    silhouette_avg = silhouette_score(comm_features, y_pred)\n",
    "    print(i, silhouette_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b187af",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = KMeans(n_clusters=5)  # 构造聚类器\n",
    "estimator.fit(comm_features)\n",
    "# print(estimator.labels_)\n",
    "# squared distance to cluster center\n",
    "dist = estimator.transform(comm_features)\n",
    "\n",
    "center_dists = np.array([dist[i][x] for i,x in enumerate(estimator.labels_)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9818ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne[estimator.labels_ == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b54457",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = estimator.labels_\n",
    "\n",
    "r = pd.Series(estimator.labels_, index = range(len(comm_features))) \n",
    "r.columns = [u'聚类类别']\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "tsne = TSNE()\n",
    "tsne.fit_transform(comm_features) \n",
    "tsne = pd.DataFrame(tsne.embedding_, index = range(len(comm_features)))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']\n",
    "plt.rcParams['axes.unicode_minus'] = False \n",
    "\n",
    "d = tsne[label == 0]     \n",
    "plt.plot(d[0], d[1], 'r.')\n",
    "d = tsne[label == 1]\n",
    "plt.plot(d[0], d[1], 'go')\n",
    "d = tsne[label == 2]\n",
    "plt.plot(d[0], d[1], 'b*')\n",
    "d = tsne[label == 3]\n",
    "plt.plot(d[0], d[1], 'y*')\n",
    "d = tsne[label == 4]\n",
    "plt.plot(d[0], d[1], 'k*')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087aba5a",
   "metadata": {},
   "source": [
    "# Abnomral Group Search and Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d12b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_acct_status = pd.read_csv('/home/binwu5/acct_status.csv')\n",
    "cust_label = dict(zip(df_acct_status['cust_id'],df_acct_status['acct_rstrd_y_n']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9165a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_groups = np.load(\"new_groups.npy\", allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dcf075b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern_features, pattern_sizes, pattern_support = get_patterns(new_groups, emb, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1fcca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"new_groups.npy\", new_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d25cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern_p = pattern_support / pattern_support.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ba4c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_mat = nx.to_scipy_sparse_matrix(nx_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8af2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse\n",
    "# scipy.sparse.save_npz('adj_mat.npz', adj_mat)\n",
    "adj_mat = scipy.sparse.load_npz('adj_mat.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49630bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_local_features = np.zeros_like(emb)\n",
    "\n",
    "for u in tqdm.tqdm(range(len(emb)), desc='NodeLocalFeature'):\n",
    "    node_local_features[u] = np.mean([emb[v] for v in (list([u]) + list([n for n in nx_g.neighbors(u)]))], axis=0)\n",
    "\n",
    "node_first_order_scores = euclidean_distances(node_local_features, pattern_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba04b471",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse as sp\n",
    "\n",
    "# Second Order: Pass 2 in the paper\n",
    "deg_vec = np.array(adj_mat.sum(1)).squeeze()\n",
    "# diags 提取对角线或构造对角线数组。\n",
    "# node_second_order_scores = sp.diags((adj_mat @ deg_vec) ** -1) @ adj_mat @ (\n",
    "#         deg_vec[:, None] * node_first_order_scores)\n",
    "\n",
    "node_degree_sum = adj_mat @ deg_vec\n",
    "node_score = adj_mat @ (deg_vec[:, None] * node_first_order_scores)\n",
    "\n",
    "node_pattern_scores = np.zeros_like(node_first_order_scores)\n",
    "\n",
    "for u in tqdm.tqdm(range(len(emb)), desc='NodeSecondFeature'):\n",
    "    if deg_vec[u] == 0:\n",
    "        node_pattern_scores[u] = node_first_order_scores[u] + 100\n",
    "    else:\n",
    "        node_pattern_scores[u] = node_first_order_scores[u] + node_score[u] / node_degree_sum[u]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37efc03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_pattern_scores = node_first_order_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160679d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_node = len(emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1960e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# used_seeds = set()\n",
    "node_degrees = np.zeros(n_cust)\n",
    "\n",
    "for u in tqdm.tqdm(range(n_cust)):\n",
    "    group = set([u])\n",
    "    for v in list([n for n in nx_g.neighbors(u)]):\n",
    "        if v >= n_cust:\n",
    "            group = group | set([n for n in nx_g.neighbors(v)])\n",
    "        else:\n",
    "            group.add(v)\n",
    "    node_degrees[u] = len(group)\n",
    "\n",
    "degree_node_dict = collections.defaultdict(list)\n",
    "    \n",
    "for i, d in enumerate(node_degrees):\n",
    "    degree_node_dict[d].append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dccbcb01",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_degrees = np.array(adj_mat.sum(1)).squeeze().astype(int)\n",
    "degree_node_dict = collections.defaultdict(list)\n",
    "for i, d in enumerate(node_degrees):\n",
    "    degree_node_dict[d].append(i)\n",
    "    \n",
    "pattern_degree_seeds = [{d: sorted(nodes, key=lambda i: -x[i])\n",
    "                                      for d, nodes in degree_node_dict.items()}\n",
    "                                     for x in node_pattern_scores.T]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624f2683",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_seed(target_size: int, degree_seeds: Dict[int, List[int]],\n",
    "             used_seeds: Set[int], eps: int = 5) -> Union[int, None]:\n",
    "    \"\"\"\n",
    "    Find the best seed that has never be picked before.\n",
    "    \"\"\"\n",
    "    for deg in range(target_size - 1, target_size + eps):\n",
    "        sorted_seeds = degree_seeds.get(deg, [])\n",
    "        # print(deg)\n",
    "        if len(sorted_seeds) == 0:\n",
    "            continue\n",
    "        while len(sorted_seeds):\n",
    "            seed = sorted_seeds.pop()\n",
    "            if seed not in used_seeds:\n",
    "                used_seeds.add(seed)\n",
    "                return seed\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e58526",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample():\n",
    "    n_try = 0\n",
    "    while (n_try < 20) and (len(used_seeds) < n_cust):\n",
    "        n_try += 1\n",
    "        pattern_id = np.random.choice(len(pattern_p), p=pattern_p)\n",
    "        target_size = np.random.choice(pattern_sizes[pattern_id])\n",
    "        seed = get_seed(target_size, pattern_degree_seeds[pattern_id], used_seeds)\n",
    "        if seed is None:\n",
    "            continue\n",
    "#         group = set([seed])\n",
    "#         for v in list([n for n in nx_g.neighbors(seed)]):\n",
    "#             if v >= n_cust:\n",
    "#                 group = group | set([n for n in nx_g.neighbors(v)])\n",
    "#                 for node in set([n for n in nx_g.neighbors(v)]):\n",
    "#                     if node < n_cust:\n",
    "#                         used_seeds.add(node)\n",
    "#             else:\n",
    "#                 group.add(v)\n",
    "#                 used_seeds.add(v)\n",
    "        # print(\"target_size:\", target_size)\n",
    "        # print(\"size:\", len(group))\n",
    "        \n",
    "        comm = [seed] + list(nx_g.neighbors(seed))\n",
    "        for node in comm:\n",
    "            used_seeds.add(node)\n",
    "        \n",
    "        return comm, pattern_id, target_size\n",
    "    \n",
    "        # return group, pattern_id, target_size\n",
    "    else:\n",
    "        raise ValueError('(Almost) Run out of seeds!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f3ad1d-4108-481c-b922-58c1e5366bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "used_seeds = set()\n",
    "pattern_degree_seeds = np.load(\"pattern_degree_seeds.npy\", allow_pickle = True)\n",
    "\n",
    "for group in new_groups:\n",
    "    for node in group:\n",
    "        used_seeds.add(node)\n",
    "\n",
    "pred_comms = []\n",
    "out_comms = []\n",
    "n_comms = 1500\n",
    "\n",
    "try:\n",
    "    for i in tqdm.tqdm(range(n_comms)):\n",
    "#         comm, pattern_id, target_size = sample()\n",
    "#         pred_comms.append(comm)\n",
    "#         custNum = 0\n",
    "#         for node in comm:\n",
    "#             if node < n_cust:\n",
    "#                 custNum += 1\n",
    "#         out_comms.append([i, pattern_id, node_pattern_scores[comm[0]][pattern_id], len(comm), custNum])\n",
    "        pred_comms.append(beam_sample(pattern_features, emb))\n",
    "except ValueError as e:\n",
    "    print('Warning!!!', e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
